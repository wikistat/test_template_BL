{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Data Science Wikistats course template This is a template for the wikistat courses. You can add your course description here. Knowledge requirements Python Tutorial Elementary statistic tools Data Exploration and Clustering . Machine Learning High Dimensional & Deep Learning","title":"Home"},{"location":"index.html#wikistats-course-template","text":"This is a template for the wikistat courses. You can add your course description here.","title":"Wikistats course template"},{"location":"index.html#knowledge-requirements","text":"Python Tutorial Elementary statistic tools Data Exploration and Clustering . Machine Learning High Dimensional & Deep Learning","title":"Knowledge requirements"},{"location":"course1.html","text":"Course 1: Writing maths in markdown In the following example, we will write some maths in a markdown file. And many things can be done with it. test $$ \\begin{aligned} \\frac{\\partial L}{\\partial \\theta} &= \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\theta} \\ &= \\frac{\\partial L}{\\partial \\hat{y}} (x_1 \\sigma_1 + x_2 \\sigma_2 + x_6\\sigma_3) \\end{aligned} $$ Embedding an image in a markdown file In the following example, we will embed an image in a markdown file. From an local image Frome an external source: Embedding a video in a markdown file In the following example, we will embed a video in a markdown file. Embedding a pdf in a markdown file In the following example, we will embed a pdf file in a markdown file. This is useful for example to embed a pdf version of a presentation.","title":"Course 1"},{"location":"course1.html#course-1","text":"","title":"Course 1:"},{"location":"course1.html#writing-maths-in-markdown","text":"In the following example, we will write some maths in a markdown file. And many things can be done with it. test $$ \\begin{aligned} \\frac{\\partial L}{\\partial \\theta} &= \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\theta} \\ &= \\frac{\\partial L}{\\partial \\hat{y}} (x_1 \\sigma_1 + x_2 \\sigma_2 + x_6\\sigma_3) \\end{aligned} $$","title":"Writing maths in markdown"},{"location":"course1.html#embedding-an-image-in-a-markdown-file","text":"In the following example, we will embed an image in a markdown file. From an local image Frome an external source:","title":"Embedding an image in a markdown file"},{"location":"course1.html#embedding-a-video-in-a-markdown-file","text":"In the following example, we will embed a video in a markdown file.","title":"Embedding a video in a markdown file"},{"location":"course1.html#embedding-a-pdf-in-a-markdown-file","text":"In the following example, we will embed a pdf file in a markdown file. This is useful for example to embed a pdf version of a presentation.","title":"Embedding a pdf in a markdown file"},{"location":"course2a.html","text":"Course 2: Example of a markdown file Practical Session In this practical session, you will now run your code through a Docker container. Using docker in data science projects has two advantages: Improving the reproducibility of the results Facilitating the portability and deployment In this session, we will try to package the code from our Gradio applications, allowing us to predict digits labels and to colorize images into a Docker image. We will then use this image to instantiate a container that could be hosted on any physical device to run the app. We will first create the Dockerfile corresponding to our environment. On your local machine, create a new file named Dockerfile containing the following code: # Base image from pytorch FROM pytorch/pytorch # Set up for your local zone an UTC information ENV TZ=Europe/Paris RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone # Additional librairies RUN pip install gradio tensorboard RUN pip install markupsafe==2.0.1 Take a moment to analyze this dockerfile. As you can see, it is built upon an existing image from Pytorch. Starting from existing images allows for fast prototyping. You may find existing images on DockerHub . The Pytorch image we will be using is available here . If docker is not already installed in your machine, follow this guide to install it. You may now build your first image using the following command: sudo docker build -t [your_image_name] [path_to_your_dockerfile] The image should take a few minutes to build. Once it is done, use the following command to list the available images on your device: sudo docker image ls How many images can you see? What do they refer to? Now that our images are built, we can use them to instantiate containers. Since a container is an instance of an image, we can instantiate several containers using a single image. We will run our first container using the interactive mode. Run the following command to run your fist container: docker run -it --name [your_container_name] [your_image_name] You should now have access to an interactive terminal within your container. On this terminal, open a Python console and check that Pytorch is installed. import torch print(torch.__version__) Quit the Python console and quit your container using ctrl+d . You can list all your running containers using the following command: sudo docker container ls Your container is closed and does not appear. To list all the existing containers, add the -a to the previous command. sudo docker container ls -a Start your containers using: sudo docker start [container_id_or_name] Check that it is now listed as started. You can have access to its interactive mode using the attach command: sudo docker attach [container_id_or_name] You can delete a container using the rm command: sudo docker rm [container_id_or_name] We will now see how to share data between the container and the machine it is running on. First create a folder containing the files: colorize_app.py mnist_app.py mnist.pth unet.pth Create a new container, this time mounting a shared volume with the following command: docker run -it --name [container_name] -v ~/[absolute_path_to_your_folder_to_share]:/workspace/[folder_name_in_the_container] [image_name] for instance: docker run -it --name my_container_name -v ~/workspace/colorize:/workspace/colorize_container my_image_name Try to run one of your Gradio applications using the interactive mode. cd [folder_name] python colorize_app.py Leave the container and look at your folder on your local machine. What can you see? Now try to run your applications on your cloud instance. Send the Dockerfile and the folder containing your applications to your cloud instance. On the cloud instance, build your image and run your container and your app in background mode. sudo docker exec -t my_container_name python ./colorize_container/colorize_app.py --weights_path ./colorize_container/unet.pth That's it! You have deployed a machine learning application on a cloud machine it is now accessible from everywhere. Send the url to one of your classmate and ask him/her to test your app. This is it for this session. Please remember to shutdown your cloud machine with the command: sudo shutdown -h now Do not hesitate to play a little more with Docker. For instance try to train the MNIST classifier directly in your container and to collect the tensorboard logs and the resulting weights on your local machine.","title":"Course 2-a"},{"location":"course2a.html#course-2","text":"","title":"Course 2:"},{"location":"course2a.html#example-of-a-markdown-file","text":"","title":"Example of a markdown file"},{"location":"course2a.html#practical-session","text":"In this practical session, you will now run your code through a Docker container. Using docker in data science projects has two advantages: Improving the reproducibility of the results Facilitating the portability and deployment In this session, we will try to package the code from our Gradio applications, allowing us to predict digits labels and to colorize images into a Docker image. We will then use this image to instantiate a container that could be hosted on any physical device to run the app. We will first create the Dockerfile corresponding to our environment. On your local machine, create a new file named Dockerfile containing the following code: # Base image from pytorch FROM pytorch/pytorch # Set up for your local zone an UTC information ENV TZ=Europe/Paris RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone # Additional librairies RUN pip install gradio tensorboard RUN pip install markupsafe==2.0.1 Take a moment to analyze this dockerfile. As you can see, it is built upon an existing image from Pytorch. Starting from existing images allows for fast prototyping. You may find existing images on DockerHub . The Pytorch image we will be using is available here . If docker is not already installed in your machine, follow this guide to install it. You may now build your first image using the following command: sudo docker build -t [your_image_name] [path_to_your_dockerfile] The image should take a few minutes to build. Once it is done, use the following command to list the available images on your device: sudo docker image ls How many images can you see? What do they refer to? Now that our images are built, we can use them to instantiate containers. Since a container is an instance of an image, we can instantiate several containers using a single image. We will run our first container using the interactive mode. Run the following command to run your fist container: docker run -it --name [your_container_name] [your_image_name] You should now have access to an interactive terminal within your container. On this terminal, open a Python console and check that Pytorch is installed. import torch print(torch.__version__) Quit the Python console and quit your container using ctrl+d . You can list all your running containers using the following command: sudo docker container ls Your container is closed and does not appear. To list all the existing containers, add the -a to the previous command. sudo docker container ls -a Start your containers using: sudo docker start [container_id_or_name] Check that it is now listed as started. You can have access to its interactive mode using the attach command: sudo docker attach [container_id_or_name] You can delete a container using the rm command: sudo docker rm [container_id_or_name] We will now see how to share data between the container and the machine it is running on. First create a folder containing the files: colorize_app.py mnist_app.py mnist.pth unet.pth Create a new container, this time mounting a shared volume with the following command: docker run -it --name [container_name] -v ~/[absolute_path_to_your_folder_to_share]:/workspace/[folder_name_in_the_container] [image_name] for instance: docker run -it --name my_container_name -v ~/workspace/colorize:/workspace/colorize_container my_image_name Try to run one of your Gradio applications using the interactive mode. cd [folder_name] python colorize_app.py Leave the container and look at your folder on your local machine. What can you see? Now try to run your applications on your cloud instance. Send the Dockerfile and the folder containing your applications to your cloud instance. On the cloud instance, build your image and run your container and your app in background mode. sudo docker exec -t my_container_name python ./colorize_container/colorize_app.py --weights_path ./colorize_container/unet.pth That's it! You have deployed a machine learning application on a cloud machine it is now accessible from everywhere. Send the url to one of your classmate and ask him/her to test your app. This is it for this session. Please remember to shutdown your cloud machine with the command: sudo shutdown -h now Do not hesitate to play a little more with Docker. For instance try to train the MNIST classifier directly in your container and to collect the tensorboard logs and the resulting weights on your local machine.","title":"Practical Session"},{"location":"course2b.html","text":"Course 2-b : Add external notebooks Practical sessions: Policy iteration and Value Iteration Q-learning Deep Q-learning","title":"Course 2-b"},{"location":"course2b.html#course-2-b","text":"","title":"Course 2-b :"},{"location":"course2b.html#add-external-notebooks","text":"Practical sessions: Policy iteration and Value Iteration Q-learning Deep Q-learning","title":"Add external notebooks"},{"location":"evaluation.html","text":"Evaluation Here is an example of a project evaluation: The evaluation is associated to the DEFI-IA (Introduction video link ) Objectives You will be evaluated on your capacity of acting like a Data Scientist , i.e. Collect the data. Doing some exploratory analysis. Create new features. Write a complete pipeline to train and test your models. Justify your modelisation choices. Interpret your results. Work in group (Git). Share it and make your results easily reproducible (Docker, Gradio). Evaluation criteria You are expected to produce a code that is easily readable and reproducible. Your code should at leat contain the three following files (but you are ecouraged to add more to make it more readable): * train.py : the training script * app.py : code to launch a gradio application to test your model (see Gradio ) * analysis.ipynb : a notebook containing your exploratory analysis and interpretability results on your model. * Dockerfile : a Dockerfile to build a docker image of your application (see Docker ) You will be evaluated on the following criteria: Project - ( 70% ): You must provide a git repository with a complete history of your commits. Your capacity to work in group will be evaluated, your commit history must contain commits from several users at different dates. You must provide a Dockerfile to build a docker image that can be used to run your code (training and the Gradio application). The git should contain a clear markdown Readme, which describes: the result you achieved the commands to run for training your model or launching the gradio application (from a docker container) The code should be clear and easily readable. No notebooks exept for the exploratory analysis. * Oral presentation - ( 30% ) 15 minutes presentation + 10 minutes questions. You will be evaluated on the following criteria: Quality of the presentation. Explanations of the chosen features and algorithm. Demonstration of your application. Some insights on your model biais and interpretability. Other details Group of 4 people (DEFI IA's team).","title":"Evaluation"},{"location":"evaluation.html#evaluation","text":"Here is an example of a project evaluation: The evaluation is associated to the DEFI-IA (Introduction video link )","title":"Evaluation"},{"location":"evaluation.html#objectives","text":"You will be evaluated on your capacity of acting like a Data Scientist , i.e. Collect the data. Doing some exploratory analysis. Create new features. Write a complete pipeline to train and test your models. Justify your modelisation choices. Interpret your results. Work in group (Git). Share it and make your results easily reproducible (Docker, Gradio).","title":"Objectives"},{"location":"evaluation.html#evaluation-criteria","text":"You are expected to produce a code that is easily readable and reproducible. Your code should at leat contain the three following files (but you are ecouraged to add more to make it more readable): * train.py : the training script * app.py : code to launch a gradio application to test your model (see Gradio ) * analysis.ipynb : a notebook containing your exploratory analysis and interpretability results on your model. * Dockerfile : a Dockerfile to build a docker image of your application (see Docker ) You will be evaluated on the following criteria: Project - ( 70% ): You must provide a git repository with a complete history of your commits. Your capacity to work in group will be evaluated, your commit history must contain commits from several users at different dates. You must provide a Dockerfile to build a docker image that can be used to run your code (training and the Gradio application). The git should contain a clear markdown Readme, which describes: the result you achieved the commands to run for training your model or launching the gradio application (from a docker container) The code should be clear and easily readable. No notebooks exept for the exploratory analysis. * Oral presentation - ( 30% ) 15 minutes presentation + 10 minutes questions. You will be evaluated on the following criteria: Quality of the presentation. Explanations of the chosen features and algorithm. Demonstration of your application. Some insights on your model biais and interpretability.","title":"Evaluation criteria"},{"location":"evaluation.html#other-details","text":"Group of 4 people (DEFI IA's team).","title":"Other details"},{"location":"schedule.html","text":"Schedule If you want to add a shedule to your course, you can use the following template. Lectures : 10 hours Practical Sessions : 30 hours. Session 1 - 26/09/2022 (9h30-12h15 & 14h00-16h45) Cours 1 : Link to the course Session 2 - 10/10/2022 (9h30-12h15 & 14h00-16h45) Course 2-a : Link to the course Course 2-a : Link to the course","title":"Schedule"},{"location":"schedule.html#schedule","text":"If you want to add a shedule to your course, you can use the following template. Lectures : 10 hours Practical Sessions : 30 hours.","title":"Schedule"},{"location":"schedule.html#session-1-26092022","text":"","title":"Session 1 - 26/09/2022"},{"location":"schedule.html#9h30-12h15-14h00-16h45","text":"Cours 1 : Link to the course","title":"(9h30-12h15 &amp; 14h00-16h45)"},{"location":"schedule.html#session-2-10102022","text":"","title":"Session 2 - 10/10/2022"},{"location":"schedule.html#9h30-12h15-14h00-16h45_1","text":"Course 2-a : Link to the course Course 2-a : Link to the course","title":"(9h30-12h15 &amp; 14h00-16h45)"}]}